import os
# 1. å¼ºåˆ¶é•œåƒåŠ é€Ÿ
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
import sys
import io
import uvicorn
import torch
import numpy as np
from PIL import Image, ImageFilter, ImageOps
from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.responses import Response
from contextlib import asynccontextmanager
from diffusers import StableDiffusionLatentUpscalePipeline

# --- è·¯å¾„é…ç½® ---
current_dir = os.path.dirname(os.path.abspath(__file__))
catvton_path = os.path.join(current_dir, "CatVTON")
sys.path.append(catvton_path)

try:
    from model.pipeline import CatVTONPipeline
    from model.cloth_masker import AutoMasker  # å¼•å…¥æœ€å¼º Mask å·¥å…·
    print("âœ… æˆåŠŸå¯¼å…¥ CatVTONPipeline å’Œ AutoMasker")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

# --- å…¨å±€å˜é‡ ---
pipeline = None
automasker = None
upscaler = None 
device = "cuda" if torch.cuda.is_available() else "cpu"

# --- æ ¸å¿ƒè¾…åŠ©å‡½æ•°ï¼šé˜²å˜å½¢ç¼©æ”¾ ---
def resize_and_padding(image, target_size):
    width, height = target_size
    w, h = image.size
    scale = min(width / w, height / h)
    new_w = int(w * scale)
    new_h = int(h * scale)
    image = image.resize((new_w, new_h), Image.LANCZOS)
    new_image = Image.new("RGB", (width, height), (127, 127, 127))
    paste_x = (width - new_w) // 2
    paste_y = (height - new_h) // 2
    new_image.paste(image, (paste_x, paste_y))
    return new_image, (paste_x, paste_y, new_w, new_h)

# --- ç”Ÿå‘½å‘¨æœŸ ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    global pipeline, automasker, upscaler
    print("ğŸš€ æ­£åœ¨åˆå§‹åŒ– CatVTON æœåŠ¡å™¨...")
    try:
        # 1. åŠ è½½ Inpainting æ¨¡å‹
        print("Loading CatVTON Pipeline...")
        pipeline = CatVTONPipeline(
            base_ckpt="booksforcharlie/stable-diffusion-inpainting",
            attn_ckpt="zhengchong/CatVTON",
            attn_ckpt_version="mix",
            weight_dtype=torch.float16,
            device=device,
            skip_safety_check=True
        )
        
        # 2. åŠ è½½ AutoMasker (DensePose + SCHP) - è¿™æ˜¯è´¨é‡çš„å…³é”®ï¼
        print("Loading AutoMasker (High Quality)...")
        # å‡è®¾æƒé‡åœ¨ CatVTON ç›®å½•ä¸‹ï¼Œæˆ–è€…è‡ªåŠ¨ä¸‹è½½
        automasker = AutoMasker(
            densepose_ckpt=os.path.join(current_dir, "CatVTON", "model", "DensePose"),
            schp_ckpt=os.path.join(current_dir, "CatVTON", "model", "SCHP"),
            device=device
        )

        # 3. (å¯é€‰) åŠ è½½æ”¾å¤§æ¨¡å‹
        # æ³¨æ„ï¼šPaste Back æŠ€æœ¯é€šå¸¸æ¯” Upscaler æ›´æœ‰æ•ˆä¸”çœæ˜¾å­˜ï¼Œè¿™é‡Œå…ˆä¿ç•™ä½†è®¾ä¸ºå¯é€‰
        # print("Loading Upscaler...")
        # upscaler = StableDiffusionLatentUpscalePipeline.from_pretrained(...)
        
        print("âœ¨ æœåŠ¡å¯åŠ¨æˆåŠŸï¼ç«¯å£: 8001")
    except Exception as e:
        print(f"ğŸ’¥ æ¨¡å‹åŠ è½½å´©æºƒ: {e}")
        import traceback
        traceback.print_exc()
    yield
    # æ¸…ç†
    del pipeline, automasker
    torch.cuda.empty_cache()

app = FastAPI(lifespan=lifespan)

@app.post("/process_tryon")
async def process_tryon(
    person_img: UploadFile = File(...),
    cloth_img: UploadFile = File(...),
    category: str = Form("upper_body") # æš‚æ—¶åªåšä¸ŠåŠèº«ï¼Œé€šç”¨æ€§æœ€å¼º
):
    global pipeline, automasker
    
    # è°ƒè¯•ç›®å½•
    debug_dir = os.path.join(current_dir, "output", "debug_server")
    os.makedirs(debug_dir, exist_ok=True)

    try:
        print(f"Processing Request: category={category}")
        
        # 1. è¯»å–å›¾ç‰‡
        person_raw = Image.open(io.BytesIO(await person_img.read())).convert("RGB")
        cloth_raw = Image.open(io.BytesIO(await cloth_img.read())).convert("RGB")

        # 2. æ™ºèƒ½ç¼©æ”¾ (768x1024)
        target_size = (768, 1024)
        person_resized, paste_info = resize_and_padding(person_raw, target_size)
        cloth_resized, _ = resize_and_padding(cloth_raw, target_size)
        
        # ä¿å­˜ä¸€ä¸‹è¾“å…¥å›¾ï¼Œæ–¹ä¾¿è°ƒè¯•
        person_resized.save(os.path.join(debug_dir, "input_person.png"))

        # 3. è‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡ Mask
        print("ğŸ” Generating Mask...")
        mask_result = automasker(person_resized, mask_type='upper')
        mask = mask_result['mask'] # è¿™æ˜¯ä¸€ä¸ª PIL Image
        
        # [å…³é”®æ­¥éª¤] ä¿å­˜ Mask æ£€æŸ¥è´¨é‡
        mask.save(os.path.join(debug_dir, "generated_mask.png"))

        # 4. Mask è¾¹ç¼˜ç¾½åŒ–
        mask_blurred = mask.filter(ImageFilter.GaussianBlur(radius=5))

        # 5. æ¨¡å‹æ¨ç†
        print("ğŸ¨ Diffusion Inference...")
        generator = torch.Generator(device=device).manual_seed(42)
        result_image = pipeline(
            image=person_resized,
            condition_image=cloth_resized,
            mask=mask_blurred,
            num_inference_steps=50, # ä¿æŒ 50 æ­¥
            guidance_scale=2.5,
            generator=generator
        )[0]
        
        # ä¿å­˜ç›´å‡ºç»“æœ
        result_image.save(os.path.join(debug_dir, "raw_output.png"))

        # 6. [æ ¸å¿ƒæŠ€æœ¯] Paste Back (å›è´´)
        # å°†ç”Ÿæˆçš„è¡£æœèåˆå›åŸå›¾ (person_resized)ï¼Œåªä¿ç•™è¡£æœåŒºåŸŸ
        # è¿™æ ·è„¸éƒ¨å’ŒèƒŒæ™¯å°±ç»å¯¹ä¸ä¼šå˜ç³Š
        print("ğŸ”§ Pasting Back...")
        
        # é‡æ–°è°ƒæ•´ mask å¤§å°ç”¨äºåˆæˆ (mask ä¹Ÿæ˜¯ 768x1024ï¼Œä¸ç”¨åŠ¨)
        mask_for_composite = mask.convert("L")
        # ç¨å¾®è…èš€ä¸€ç‚¹ Maskï¼Œé˜²æ­¢ç™½è¾¹
        mask_for_composite = mask_for_composite.filter(ImageFilter.GaussianBlur(radius=1))
        
        # ç»„åˆï¼šMask ç™½è‰²åŒºåŸŸç”¨æ–°å›¾ï¼Œé»‘è‰²åŒºåŸŸç”¨åŸå›¾
        final_image = Image.composite(result_image, person_resized, mask_for_composite)
        
        # (å¯é€‰) å¦‚æœéœ€è¦è¿˜åŸå›ç”¨æˆ·åŸå§‹ä¸Šä¼ å›¾ç‰‡çš„å°ºå¯¸ï¼Œå¯ä»¥åœ¨è¿™é‡Œåšåå‘ Crop
        # ä½†é€šå¸¸ Web ç«¯å±•ç¤º 768x1024 å°±å¤Ÿäº†

        # 7. è¿”å›ç»“æœ
        img_byte_arr = io.BytesIO()
        final_image.save(img_byte_arr, format='PNG')
        return Response(content=img_byte_arr.getvalue(), media_type="image/png")

    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"AI Error: {str(e)}")

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8001)