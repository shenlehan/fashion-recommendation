import os
# 1. å¼ºåˆ¶é•œåƒåŠ é€Ÿ
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
import sys
import io
import uvicorn
import torch
import numpy as np
from PIL import Image, ImageFilter, ImageOps
from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.responses import Response
from typing import List
import json
from contextlib import asynccontextmanager
from diffusers import StableDiffusionLatentUpscalePipeline

# --- è·¯å¾„é…ç½® ---
current_dir = os.path.dirname(os.path.abspath(__file__))
catvton_path = os.path.join(current_dir, "CatVTON")
sys.path.append(catvton_path)

try:
    from model.pipeline import CatVTONPipeline
    from model.cloth_masker import AutoMasker  # å¼•å…¥æœ€å¼º Mask å·¥å…·
    print("æˆåŠŸå¯¼å…¥ CatVTONPipeline å’Œ AutoMasker")
except ImportError as e:
    print(f"å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

# --- å…¨å±€å˜é‡ ---
pipeline = None
automasker = None
upscaler = None 
device = "cuda" if torch.cuda.is_available() else "cpu"

# --- ç±»åˆ« â†’ mask_type æ˜ å°„ ---
CATEGORY_TO_MASK_TYPE = {
    'inner_top': 'upper',
    'mid_top': 'upper', 
    'outer_top': 'outer',
    'bottom': 'lower',
    'full_body': 'overall',
}

# --- è¯•ç©¿é¡ºåºä¼˜å…ˆçº§ï¼ˆæ•°å­—è¶Šå°è¶Šå…ˆç©¿ï¼‰---
CATEGORY_PRIORITY = {
    'inner_top': 10,
    'mid_top': 20,
    'outer_top': 30,
    'bottom': 40,
    'full_body': 50,
}

# --- æ ¸å¿ƒè¾…åŠ©å‡½æ•°ï¼šé˜²å˜å½¢ç¼©æ”¾ ---
def resize_and_padding(image, target_size):
    width, height = target_size
    w, h = image.size
    scale = min(width / w, height / h)
    new_w = int(w * scale)
    new_h = int(h * scale)
    image = image.resize((new_w, new_h), Image.LANCZOS)
    new_image = Image.new("RGB", (width, height), (127, 127, 127))
    paste_x = (width - new_w) // 2
    paste_y = (height - new_h) // 2
    new_image.paste(image, (paste_x, paste_y))
    return new_image, (paste_x, paste_y, new_w, new_h)

# --- ç”Ÿå‘½å‘¨æœŸ ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    global pipeline, automasker, upscaler
    print("æ­£åœ¨åˆå§‹åŒ– CatVTON æœåŠ¡å™¨...")
    try:
        # 1. åŠ è½½ Inpainting æ¨¡å‹
        print("Loading CatVTON Pipeline...")
        pipeline = CatVTONPipeline(
            base_ckpt="booksforcharlie/stable-diffusion-inpainting",
            attn_ckpt="zhengchong/CatVTON",
            attn_ckpt_version="mix",
            weight_dtype=torch.float16,
            device=device,
            skip_safety_check=True
        )
        
        # 2. åŠ è½½ AutoMasker (DensePose + SCHP) - è¿™æ˜¯è´¨é‡çš„å…³é”®ï¼
        print("Loading AutoMasker (High Quality)...")
        # å‡è®¾æƒé‡åœ¨ CatVTON ç›®å½•ä¸‹ï¼Œæˆ–è€…è‡ªåŠ¨ä¸‹è½½
        automasker = AutoMasker(
            densepose_ckpt=os.path.join(current_dir, "CatVTON", "model", "DensePose"),
            schp_ckpt=os.path.join(current_dir, "CatVTON", "model", "SCHP"),
            device=device
        )

        # 3. (å¯é€‰) åŠ è½½æ”¾å¤§æ¨¡å‹
        # Paste BackæŠ€æœ¯é€šå¸¸æ¯”Upscaleræ›´æœ‰æ•ˆä¸”çœæ˜¾å­˜ï¼Œè¿™é‡Œå…ˆä¿ç•™ä½†è®¾ä¸ºå¯é€‰
        # print("Loading Upscaler...")
        # upscaler = StableDiffusionLatentUpscalePipeline.from_pretrained(...)
        
        print("æœåŠ¡å¯åŠ¨æˆåŠŸï¼ç«¯å£: 8001")
    except Exception as e:
        print(f"æ¨¡å‹åŠ è½½å´©æºƒ: {e}")
        import traceback
        traceback.print_exc()
    yield
    # æ¸…ç†
    del pipeline, automasker
    torch.cuda.empty_cache()

app = FastAPI(lifespan=lifespan)

@app.post("/process_tryon")
async def process_tryon(
    person_img: UploadFile = File(...),
    cloth_img: UploadFile = File(...),
    category: str = Form("upper_body") # æš‚æ—¶åªåšä¸ŠåŠèº«ï¼Œé€šç”¨æ€§æœ€å¼º
):
    global pipeline, automasker
    
    # è°ƒè¯•ç›®å½•
    debug_dir = os.path.join(current_dir, "output", "debug_server")
    os.makedirs(debug_dir, exist_ok=True)

    try:
        print(f"Processing Request: category={category}")
        
        # 1. è¯»å–å›¾ç‰‡
        person_raw = Image.open(io.BytesIO(await person_img.read())).convert("RGB")
        cloth_raw = Image.open(io.BytesIO(await cloth_img.read())).convert("RGB")

        # 2. æ™ºèƒ½ç¼©æ”¾ (768x1024)
        target_size = (768, 1024)
        person_resized, paste_info = resize_and_padding(person_raw, target_size)
        cloth_resized, _ = resize_and_padding(cloth_raw, target_size)
        
        # ä¿å­˜ä¸€ä¸‹è¾“å…¥å›¾ï¼Œæ–¹ä¾¿è°ƒè¯•
        person_resized.save(os.path.join(debug_dir, "input_person.png"))

        # 3. è‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡ Mask
        print("Generating Mask...")
        mask_result = automasker(person_resized, mask_type='upper')
        mask = mask_result['mask'] # è¿™æ˜¯ä¸€ä¸ª PIL Image
        
        # [å…³é”®æ­¥éª¤] ä¿å­˜ Mask æ£€æŸ¥è´¨é‡
        mask.save(os.path.join(debug_dir, "generated_mask.png"))

        # 4. Mask è¾¹ç¼˜ç¾½åŒ–
        mask_blurred = mask.filter(ImageFilter.GaussianBlur(radius=5))

        # 5. æ¨¡å‹æ¨ç†
        print("æ¨¡å‹æ¨ç†ä¸­...")
        generator = torch.Generator(device=device).manual_seed(42)
        result_image = pipeline(
            image=person_resized,
            condition_image=cloth_resized,
            mask=mask_blurred,
            num_inference_steps=50, # ä¿æŒ 50 æ­¥
            guidance_scale=2.5,
            generator=generator
        )[0]
        
        # ä¿å­˜ç›´å‡ºç»“æœ
        result_image.save(os.path.join(debug_dir, "raw_output.png"))

        # 6. [æ ¸å¿ƒæŠ€æœ¯] Paste Back (å›è´´)
        # å°†ç”Ÿæˆçš„è¡£æœèåˆå›åŸå›¾ (person_resized)ï¼Œåªä¿ç•™è¡£æœåŒºåŸŸ
        # è¿™æ ·è„¸éƒ¨å’ŒèƒŒæ™¯å°±ç»å¯¹ä¸ä¼šå˜ç³Š
        print("Pasting Back...")
        
        # é‡æ–°è°ƒæ•´ mask å¤§å°ç”¨äºåˆæˆ (mask ä¹Ÿæ˜¯ 768x1024ï¼Œä¸ç”¨åŠ¨)
        mask_for_composite = mask.convert("L")
        # ç¨å¾®è…èš€ä¸€ç‚¹ Maskï¼Œé˜²æ­¢ç™½è¾¹
        mask_for_composite = mask_for_composite.filter(ImageFilter.GaussianBlur(radius=1))
        
        # ç»„åˆï¼šMask ç™½è‰²åŒºåŸŸç”¨æ–°å›¾ï¼Œé»‘è‰²åŒºåŸŸç”¨åŸå›¾
        final_image = Image.composite(result_image, person_resized, mask_for_composite)
        
        # (å¯é€‰) å¦‚æœéœ€è¦è¿˜åŸå›ç”¨æˆ·åŸå§‹ä¸Šä¼ å›¾ç‰‡çš„å°ºå¯¸ï¼Œå¯ä»¥åœ¨è¿™é‡Œåšåå‘ Crop
        # ä½†é€šå¸¸ Web ç«¯å±•ç¤º 768x1024 å°±å¤Ÿäº†

        # 7. è¿”å›ç»“æœ
        img_byte_arr = io.BytesIO()
        final_image.save(img_byte_arr, format='PNG')
        return Response(content=img_byte_arr.getvalue(), media_type="image/png")

    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"AI Error: {str(e)}")

@app.post("/batch_tryon")
async def batch_tryon(
    person_img: UploadFile = File(...),
    cloth_imgs: List[UploadFile] = File(...),
    categories: str = Form(...)
):
    """æ‰¹é‡è¯•ç©¿ï¼šæŒ‰é¡ºåºä¾æ¬¡è¯•ç©¿å¤šä»¶è¡£æœ"""
    global pipeline, automasker
    
    debug_dir = os.path.join(current_dir, "output", "debug_batch")
    os.makedirs(debug_dir, exist_ok=True)
    
    try:
        # 1. è§£æç±»åˆ«åˆ—è¡¨
        category_list = json.loads(categories)
        print(f"ğŸ“¦ æ”¶åˆ°æ‰¹é‡è¯•ç©¿è¯·æ±‚: {len(cloth_imgs)} ä»¶è¡£æœ, ç±»åˆ«: {category_list}")
        
        # 2. è¯»å–æ‰€æœ‰è¡£æœå›¾ç‰‡
        cloth_images = []
        for cloth_file in cloth_imgs:
            cloth_raw = Image.open(io.BytesIO(await cloth_file.read())).convert("RGB")
            cloth_images.append(cloth_raw)
        
        # 3. æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆå†…å±‚â†’å¤–å±‚â†’ä¸‹è£…ï¼‰
        items = list(zip(category_list, cloth_images))
        items.sort(key=lambda x: CATEGORY_PRIORITY.get(x[0], 99))
        
        # 4. è¯»å–äººåƒ
        person_raw = Image.open(io.BytesIO(await person_img.read())).convert("RGB")
        target_size = (768, 1024)
        current_person, _ = resize_and_padding(person_raw, target_size)
        
        # ä¿å­˜åŸå§‹äººåƒç”¨äºè°ƒè¯•
        current_person.save(os.path.join(debug_dir, "input_person.png"))
        
        # 5. é¡ºåºæ¨ç†
        for i, (category, cloth_raw) in enumerate(items):
            print(f"è¯•ç©¿ç¬¬ {i+1}/{len(items)} ä»¶: {category}")
            
            mask_type = CATEGORY_TO_MASK_TYPE.get(category, 'upper')
            cloth_resized, _ = resize_and_padding(cloth_raw, target_size)
            
            # ä¿å­˜è¡£æœå›¾ç‰‡ç”¨äºè°ƒè¯•
            cloth_resized.save(os.path.join(debug_dir, f"cloth_{i+1}_{category}.png"))
            
            # ç”Ÿæˆ mask
            print(f"ç”Ÿæˆ mask (type={mask_type})...")
            mask_result = automasker(current_person, mask_type=mask_type)
            mask = mask_result['mask']
            mask.save(os.path.join(debug_dir, f"mask_{i+1}_{category}.png"))
            mask_blurred = mask.filter(ImageFilter.GaussianBlur(radius=5))
            
            # æ¨ç†
            print(f"æ¨¡å‹æ¨ç†ä¸­...")
            generator = torch.Generator(device=device).manual_seed(42)
            result_image = pipeline(
                image=current_person,
                condition_image=cloth_resized,
                mask=mask_blurred,
                num_inference_steps=50,
                guidance_scale=2.5,
                generator=generator
            )[0]
            
            # Paste Back
            mask_for_composite = mask.convert("L").filter(ImageFilter.GaussianBlur(radius=1))
            current_person = Image.composite(result_image, current_person, mask_for_composite)
            
            # ä¿å­˜ä¸­é—´ç»“æœ
            current_person.save(os.path.join(debug_dir, f"step_{i+1}_{category}.png"))
            print(f"ç¬¬ {i+1} ä»¶å®Œæˆ")
        
        # 6. è¿”å›æœ€ç»ˆç»“æœ
        print(f"æ‰¹é‡è¯•ç©¿å®Œæˆï¼å…± {len(items)} ä»¶")
        img_byte_arr = io.BytesIO()
        current_person.save(img_byte_arr, format='PNG')
        return Response(content=img_byte_arr.getvalue(), media_type="image/png")
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡è¯•ç©¿å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8001)