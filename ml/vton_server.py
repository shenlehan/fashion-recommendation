import os
# 1. å¼ºåˆ¶é•œåƒåŠ é€Ÿ (é˜²æ­¢é‡å¯åç¯å¢ƒå˜é‡ä¸¢å¤±)
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
from PIL import Image, ImageFilter
import sys
import io
import uvicorn
import torch
import numpy as np
from PIL import Image
from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.responses import Response
from contextlib import asynccontextmanager
from transformers import SegformerImageProcessor, AutoModelForSemanticSegmentation
from diffusers import StableDiffusionLatentUpscalePipeline  # <--- é«˜æ¸…æ ¸å¿ƒç»„ä»¶

# --- è·¯å¾„é…ç½® ---
current_dir = os.path.dirname(os.path.abspath(__file__))
catvton_path = os.path.join(current_dir, "CatVTON")
sys.path.append(catvton_path)

try:
    from model.pipeline import CatVTONPipeline
    print("âœ… æˆåŠŸå¯¼å…¥ CatVTONPipeline")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

# --- å…¨å±€å˜é‡ ---
pipeline = None
upscaler = None     # <--- æ”¾å¤§æ¨¡å‹
seg_processor = None
seg_model = None
device = "cuda" if torch.cuda.is_available() else "cpu"

# --- è¾…åŠ©å‡½æ•°ï¼šè‡ªåŠ¨ Mask ---
def get_accurate_mask(image, category):
    global seg_processor, seg_model, device
    inputs = seg_processor(images=image, return_tensors="pt").to(device)
    with torch.no_grad():
        outputs = seg_model(**inputs)
        logits = outputs.logits
    
    upsampled_logits = torch.nn.functional.interpolate(
        logits, size=image.size[::-1], mode="bilinear", align_corners=False,
    )
    pred_seg = upsampled_logits.argmax(dim=1)[0]
    mask_tensor = torch.zeros_like(pred_seg, dtype=torch.float32)
    
    # æ ‡ç­¾æ˜ å°„
    if category == "upper_body":
        target_labels = [4, 14, 15] 
    elif category == "lower_body":
        target_labels = [5, 6, 12, 13]
    elif category == "dresses":
        target_labels = [4, 5, 7, 12, 13, 14, 15]
    else:
        target_labels = [4, 14, 15]

    for label in target_labels:
        mask_tensor[pred_seg == label] = 1.0
        
    mask_np = mask_tensor.cpu().numpy() * 255
    return Image.fromarray(mask_np.astype(np.uint8)).convert("L")

# --- ç”Ÿå‘½å‘¨æœŸ ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    global pipeline, upscaler, seg_processor, seg_model
    print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–é«˜æ¸…ç³»ç»Ÿ...")
    try:
        # 1. åŠ è½½ Inpainting æ¨¡å‹
        print("Loading CatVTON...")
        pipeline = CatVTONPipeline(
            base_ckpt="runwayml/stable-diffusion-inpainting",
            attn_ckpt="zhengchong/CatVTON",
            attn_ckpt_version="mix",
            weight_dtype=torch.float16,
            device=device,
            skip_safety_check=True
        )
        
        # 2. åŠ è½½æ”¾å¤§æ¨¡å‹ (å…³é”®ä¸€æ­¥ï¼)
        print("Loading Upscaler (HD Mode)...")
        # å¦‚æœæ¨¡å‹å·²ç»ä¸‹è½½å¥½ï¼Œè¿™é‡Œä¼šç¬é—´åŠ è½½å®Œæˆ
        upscaler = StableDiffusionLatentUpscalePipeline.from_pretrained(
            "stabilityai/sd-x2-latent-upscaler",
            torch_dtype=torch.float16
        )
        # æ˜¾å­˜ä¼˜åŒ–ï¼šå¹³æ—¶æ”¾å†…å­˜ï¼Œç”¨æ—¶æ‰ä¸Šæ˜¾å¡ï¼Œé˜²æ­¢æ˜¾å­˜çˆ†ç‚¸
        upscaler.enable_model_cpu_offload()

        # 3. åŠ è½½ SegFormer
        print("Loading SegFormer...")
        seg_processor = SegformerImageProcessor.from_pretrained("mattmdjaga/segformer_b2_clothes")
        seg_model = AutoModelForSemanticSegmentation.from_pretrained("mattmdjaga/segformer_b2_clothes").to(device)
        
        print("âœ¨ é«˜æ¸…ç‰ˆæœåŠ¡å°±ç»ªï¼æ”¯æŒ 1536x2048 åˆ†è¾¨ç‡ï¼ç«¯å£: 8001")
    except Exception as e:
        print(f"ğŸ’¥ æ¨¡å‹åŠ è½½å´©æºƒ: {e}")
        raise e
    yield
    del pipeline, upscaler, seg_model
    torch.cuda.empty_cache()

app = FastAPI(lifespan=lifespan)

@app.post("/process_tryon")
async def process_tryon(
    person_img: UploadFile = File(...),
    cloth_img: UploadFile = File(...),
    category: str = Form("upper_body")
):
    global pipeline, upscaler
    if pipeline is None:
        raise HTTPException(status_code=503, detail="Model not loaded")

    try:
        print(f"Processing Try-On: category={category}")
        
        # 1. è¯»å–
        image = Image.open(io.BytesIO(await person_img.read())).convert("RGB")
        cloth = Image.open(io.BytesIO(await cloth_img.read())).convert("RGB")

        # 2. Resize (å®˜æ–¹ Demo æ ‡å‡†åˆ†è¾¨ç‡)
        target_size = (768, 1024)
        image = image.resize(target_size, Image.Resampling.LANCZOS)
        cloth = cloth.resize(target_size, Image.Resampling.LANCZOS)

        # 3. Mask & å…³é”®æ¨¡ç³Šå¤„ç†
        mask = get_accurate_mask(image, category)
        # æ ¸å¿ƒä¼˜åŒ–ï¼šé«˜æ–¯æ¨¡ç³Šï¼Œæ¶ˆé™¤è´´çº¸æ„Ÿ
        mask = mask.filter(ImageFilter.GaussianBlur(radius=5)) 

        # 4. æ¨ç† (ç¬¬ä¸€é˜¶æ®µï¼šç”Ÿæˆåº•å›¾)
        output = pipeline(
            image=image,
            condition_image=cloth,
            mask=mask, 
            num_inference_steps=50, # æå‡è‡³ 50 æ­¥ä»¥è·å¾—æœ€ä½³è´¨æ„Ÿ
            guidance_scale=2.5
        )

        if isinstance(output, list):
            base_img = output[0]
        elif hasattr(output, 'images'):
            base_img = output.images[0]
        else:
            base_img = output

        # 5. é«˜æ¸…æ”¾å¤§ (ç¬¬äºŒé˜¶æ®µï¼šç»†èŠ‚å¢å¼º)
        # æ³¨æ„ï¼šå¦‚æœæ˜¾å­˜ç´§å¼ ï¼Œå¯ä»¥æŠŠè¿™æ­¥å»æ‰ï¼Œ768x1024 çš„è´¨é‡å·²ç»å¾ˆé«˜äº†
        print("ğŸ” æ­£åœ¨è¿›è¡Œ 2x é«˜æ¸…æ”¾å¤§...")
        upscaled_result = upscaler(
            prompt="",
            image=base_img,
            num_inference_steps=20,
            guidance_scale=0,
            generator=torch.manual_seed(42)
        ).images[0]

        # 6. è¿”å›é«˜æ¸…å›¾
        img_byte_arr = io.BytesIO()
        upscaled_result.save(img_byte_arr, format='PNG')
        return Response(content=img_byte_arr.getvalue(), media_type="image/png")

    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"AI Error: {str(e)}")

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8001)